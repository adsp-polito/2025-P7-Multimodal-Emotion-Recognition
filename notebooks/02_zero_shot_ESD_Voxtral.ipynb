{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dab23f68125a431cb909b64a374b18dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_200eea3f8254425caf9b1070abc49830",
              "IPY_MODEL_34c9453bee8c42fb87d7dc23249bd238",
              "IPY_MODEL_04f96bae8a954ee395af0f40822b3a7c"
            ],
            "layout": "IPY_MODEL_6e4eff4a024649b790f201bfcdd59f85"
          }
        },
        "200eea3f8254425caf9b1070abc49830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b050908d27d425e868f6195c1d2311b",
            "placeholder": "​",
            "style": "IPY_MODEL_08da0f7bf23a4c56b4b635475790e21f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "34c9453bee8c42fb87d7dc23249bd238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a81cdd89d3a44bea84d28e86f5d0ac0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f848d5ead1045ed91c757527f2f2dca",
            "value": 2
          }
        },
        "04f96bae8a954ee395af0f40822b3a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_418800cae6a949898a061478f0e85951",
            "placeholder": "​",
            "style": "IPY_MODEL_a5a0e92d9375452da6cefbca7ef041ea",
            "value": " 2/2 [00:56&lt;00:00, 28.49s/it]"
          }
        },
        "6e4eff4a024649b790f201bfcdd59f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b050908d27d425e868f6195c1d2311b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08da0f7bf23a4c56b4b635475790e21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a81cdd89d3a44bea84d28e86f5d0ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f848d5ead1045ed91c757527f2f2dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "418800cae6a949898a061478f0e85951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5a0e92d9375452da6cefbca7ef041ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1653b5639bca458b8647727ddf7cc145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4da26cfee56d4ce0a00a1437d0d9bbdd",
              "IPY_MODEL_631554640100411682e2d4473949df95",
              "IPY_MODEL_143715811c0847ffa16f30afa2baaaff"
            ],
            "layout": "IPY_MODEL_7701bfabf3b34c76a0c8f7e9467a6ec6"
          }
        },
        "4da26cfee56d4ce0a00a1437d0d9bbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da52c683bf71401eb9f318429b699ea3",
            "placeholder": "​",
            "style": "IPY_MODEL_38757bf0cbe24357850260eaf0032282",
            "value": "  0%"
          }
        },
        "631554640100411682e2d4473949df95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d1163e136e94c918c7ffa611f0aab12",
            "max": 1750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d580236723b46a6888f086d7e94962f",
            "value": 2
          }
        },
        "143715811c0847ffa16f30afa2baaaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f51a2d4710f46a0949e71f7f225f45b",
            "placeholder": "​",
            "style": "IPY_MODEL_b84b3bf3c47140bf88a9947f1a3a7308",
            "value": " 2/1750 [01:47&lt;23:35:50, 48.60s/it]"
          }
        },
        "7701bfabf3b34c76a0c8f7e9467a6ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da52c683bf71401eb9f318429b699ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38757bf0cbe24357850260eaf0032282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d1163e136e94c918c7ffa611f0aab12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d580236723b46a6888f086d7e94962f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f51a2d4710f46a0949e71f7f225f45b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b84b3bf3c47140bf88a9947f1a3a7308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 0. INSTALLS & IMPORTS\n",
        "# ============================================\n",
        "!pip install -q \"transformers>=4.46.0\" \"mistral_common[audio]>=1.8.6\" \"accelerate>=0.34.0\" pandas einops\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from transformers import VoxtralForConditionalGeneration, AutoProcessor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    precision_recall_fscore_support,\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# 1. BUILD DATAFRAME (UNCHANGED)\n",
        "# ============================================\n",
        "ROOT_DIR = \"/content/drive/MyDrive/adsp/downloads/ESD/Emotion Speech Dataset\"\n",
        "EN_SPEAKERS = [f\"{i:04d}\" for i in range(11, 21)]  # 0011–0020 are English\n",
        "\n",
        "rows = []\n",
        "\n",
        "for spk in EN_SPEAKERS:\n",
        "    txt_path = os.path.join(ROOT_DIR, spk, f\"{spk}.txt\")\n",
        "    if not os.path.exists(txt_path):\n",
        "        print(f\"[WARN] transcript missing: {txt_path}\")\n",
        "        continue\n",
        "\n",
        "    with open(txt_path, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            parts = line.split()\n",
        "            utt_id = parts[0]          # e.g. 0011_000001\n",
        "            emo    = parts[-1]         # Angry / Happy / Neutral / Sad / Surprise\n",
        "            sent   = \" \".join(parts[1:-1])\n",
        "\n",
        "            wav_path = os.path.join(ROOT_DIR, spk, emo, f\"{utt_id}.wav\")\n",
        "            if not os.path.exists(wav_path):\n",
        "                cands = glob.glob(\n",
        "                    os.path.join(ROOT_DIR, spk, \"**\", f\"{utt_id}.wav\"),\n",
        "                    recursive=True\n",
        "                )\n",
        "                if not cands:\n",
        "                    print(f\"[MISS] audio for {utt_id}\")\n",
        "                    continue\n",
        "                wav_path = cands[0]\n",
        "\n",
        "            rows.append({\n",
        "                \"speaker\": spk,\n",
        "                \"utt_id\": utt_id,\n",
        "                \"audio_path\": wav_path,\n",
        "                \"transcript\": sent,\n",
        "                \"emotion\": emo,\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(\"Total English utterances:\", len(df))\n",
        "display(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "Rri-nowz7hma",
        "outputId": "c0a92425-85a7-468a-bb71-f43e10983b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total English utterances: 17500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  speaker       utt_id                                         audio_path  \\\n",
              "0    0011  0011_000001  /content/drive/MyDrive/adsp/downloads/ESD/Emot...   \n",
              "1    0011  0011_000002  /content/drive/MyDrive/adsp/downloads/ESD/Emot...   \n",
              "2    0011  0011_000003  /content/drive/MyDrive/adsp/downloads/ESD/Emot...   \n",
              "3    0011  0011_000004  /content/drive/MyDrive/adsp/downloads/ESD/Emot...   \n",
              "4    0011  0011_000005  /content/drive/MyDrive/adsp/downloads/ESD/Emot...   \n",
              "\n",
              "                                          transcript  emotion  \n",
              "0                         The nine the eggs, I keep.  Neutral  \n",
              "1                 I did go, and made many prisoners.  Neutral  \n",
              "2                       That I owe my thanks to you.  Neutral  \n",
              "3  They went up to the dark mass job had pointed ...  Neutral  \n",
              "4                            Clear than clear water!  Neutral  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89ac33b1-a765-4f13-ba1e-1ebdd204415f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>utt_id</th>\n",
              "      <th>audio_path</th>\n",
              "      <th>transcript</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0011</td>\n",
              "      <td>0011_000001</td>\n",
              "      <td>/content/drive/MyDrive/adsp/downloads/ESD/Emot...</td>\n",
              "      <td>The nine the eggs, I keep.</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0011</td>\n",
              "      <td>0011_000002</td>\n",
              "      <td>/content/drive/MyDrive/adsp/downloads/ESD/Emot...</td>\n",
              "      <td>I did go, and made many prisoners.</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0011</td>\n",
              "      <td>0011_000003</td>\n",
              "      <td>/content/drive/MyDrive/adsp/downloads/ESD/Emot...</td>\n",
              "      <td>That I owe my thanks to you.</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0011</td>\n",
              "      <td>0011_000004</td>\n",
              "      <td>/content/drive/MyDrive/adsp/downloads/ESD/Emot...</td>\n",
              "      <td>They went up to the dark mass job had pointed ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0011</td>\n",
              "      <td>0011_000005</td>\n",
              "      <td>/content/drive/MyDrive/adsp/downloads/ESD/Emot...</td>\n",
              "      <td>Clear than clear water!</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89ac33b1-a765-4f13-ba1e-1ebdd204415f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89ac33b1-a765-4f13-ba1e-1ebdd204415f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89ac33b1-a765-4f13-ba1e-1ebdd204415f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df71ac19-1f0b-44a4-8ed0-f7e1cf785d25\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df71ac19-1f0b-44a4-8ed0-f7e1cf785d25')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df71ac19-1f0b-44a4-8ed0-f7e1cf785d25 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0011\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"utt_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"0011_000002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/drive/MyDrive/adsp/downloads/ESD/Emotion Speech Dataset/0011/Neutral/0011_000002.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I did go, and made many prisoners.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 2. LOAD MODEL (SAME, BUT KEEP IT CLEAN)\n",
        "# ============================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "REPO_ID = \"mistralai/Voxtral-Mini-3B-2507\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(REPO_ID, trust_remote_code=True)\n",
        "model = VoxtralForConditionalGeneration.from_pretrained(\n",
        "    REPO_ID,\n",
        "    torch_dtype=torch.bfloat16 if device == \"cuda\" else torch.float32,\n",
        "    device_map=device,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model.eval()\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "LABELS = [\"Angry\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210,
          "referenced_widgets": [
            "dab23f68125a431cb909b64a374b18dd",
            "200eea3f8254425caf9b1070abc49830",
            "34c9453bee8c42fb87d7dc23249bd238",
            "04f96bae8a954ee395af0f40822b3a7c",
            "6e4eff4a024649b790f201bfcdd59f85",
            "7b050908d27d425e868f6195c1d2311b",
            "08da0f7bf23a4c56b4b635475790e21f",
            "9a81cdd89d3a44bea84d28e86f5d0ac0",
            "5f848d5ead1045ed91c757527f2f2dca",
            "418800cae6a949898a061478f0e85951",
            "a5a0e92d9375452da6cefbca7ef041ea"
          ]
        },
        "id": "j8AyHW-W7l12",
        "outputId": "7d547b86-2165-4a53-a95a-0677db3a12cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dab23f68125a431cb909b64a374b18dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3. LABEL NORMALIZATION (UNCHANGED)\n",
        "# ============================================\n",
        "def normalize_label(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    for lab in LABELS:\n",
        "        if lab.lower() in text:\n",
        "            return lab\n",
        "    words = re.findall(r\"[a-zA-Z]+\", text)\n",
        "    for w in words:\n",
        "        for lab in LABELS:\n",
        "            if w == lab.lower():\n",
        "                return lab\n",
        "    return \"Unknown\"\n"
      ],
      "metadata": {
        "id": "PCovGIEO7rPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 4. SINGLE-SAMPLE PREDICTOR (FOR DEBUGGING)\n",
        "#    (unchanged semantics)\n",
        "# ============================================\n",
        "def voxtral_predict(audio_path: str,\n",
        "                    transcript: str = \"\",\n",
        "                    use_text: bool = False,\n",
        "                    max_new_tokens: int = 3) -> str:\n",
        "    \"\"\"\n",
        "    Zero-shot emotion prediction for a single sample.\n",
        "    use_text = False -> audio only\n",
        "    use_text = True  -> audio + transcript\n",
        "    \"\"\"\n",
        "    file_url = \"file://\" + os.path.abspath(audio_path)\n",
        "\n",
        "    content = [\n",
        "        {\n",
        "            \"type\": \"audio_url\",\n",
        "            \"audio_url\": file_url,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if use_text and transcript.strip():\n",
        "        content.append({\"type\": \"text\", \"text\": f\"Transcript: {transcript}\"})\n",
        "\n",
        "    content.append({\n",
        "        \"type\": \"text\",\n",
        "        \"text\": (\n",
        "            \"Classify the speaker's emotion. \"\n",
        "            \"Answer with ONLY one word from [Angry, Happy, Neutral, Sad, Surprise].\"\n",
        "        ),\n",
        "    })\n",
        "\n",
        "    conversation = [{\"role\": \"user\", \"content\": content}]\n",
        "\n",
        "    inputs = processor.apply_chat_template(\n",
        "        conversation,\n",
        "        tokenize=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=False,\n",
        "        )\n",
        "\n",
        "    new_tokens = outputs[:, inputs[\"input_ids\"].shape[1]:]\n",
        "    decoded = processor.batch_decode(new_tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "    return normalize_label(decoded)\n",
        "\n",
        "\n",
        "# Quick sanity check on one row (OPTIONAL)\n",
        "row = df.iloc[0]\n",
        "print(\"Audio:\", row.audio_path)\n",
        "print(\"Transcript:\", row.transcript)\n",
        "print(\"Gold:\", row.emotion)\n",
        "\n",
        "print(\"Pred (audio only):\", voxtral_predict(row.audio_path, use_text=False))\n",
        "print(\"Pred (audio + text):\", voxtral_predict(row.audio_path, row.transcript, use_text=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gx8XZGU7vFq",
        "outputId": "c1c9a525-ac14-47fc-da86-ca2090a62d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio: /content/drive/MyDrive/adsp/downloads/ESD/Emotion Speech Dataset/0011/Neutral/0011_000001.wav\n",
            "Transcript: The nine the eggs, I keep.\n",
            "Gold: Neutral\n",
            "Pred (audio only): Happy\n",
            "Pred (audio + text): Happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5. BATCHED PREDICTION (FASTER PART)\n",
        "# ============================================\n",
        "def build_conversation_for_row(audio_path: str,\n",
        "                               transcript: str,\n",
        "                               use_text: bool) -> dict:\n",
        "    \"\"\"Create one-chat turn for a given row, matching the single-sample logic.\"\"\"\n",
        "    file_url = \"file://\" + os.path.abspath(audio_path)\n",
        "\n",
        "    content = [\n",
        "        {\n",
        "            \"type\": \"audio_url\",\n",
        "            \"audio_url\": file_url,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if use_text and transcript.strip():\n",
        "        content.append({\"type\": \"text\", \"text\": f\"Transcript: {transcript}\"})\n",
        "\n",
        "    content.append({\n",
        "        \"type\": \"text\",\n",
        "        \"text\": (\n",
        "            \"Classify the speaker's emotion. \"\n",
        "            \"Answer with ONLY one word from [Angry, Happy, Neutral, Sad, Surprise].\"\n",
        "        ),\n",
        "    })\n",
        "\n",
        "    return {\"role\": \"user\", \"content\": content}\n",
        "\n",
        "\n",
        "def voxtral_predict_batch(df_batch: pd.DataFrame,\n",
        "                          use_text: bool,\n",
        "                          max_new_tokens: int = 3) -> list[str]:\n",
        "    \"\"\"\n",
        "    Batched zero-shot prediction for a slice of the dataframe.\n",
        "    Returns list of labels (same order as df_batch).\n",
        "    \"\"\"\n",
        "    conversations = []\n",
        "    for _, row in df_batch.iterrows():\n",
        "        conv = [build_conversation_for_row(\n",
        "            audio_path=row[\"audio_path\"],\n",
        "            transcript=row[\"transcript\"],\n",
        "            use_text=use_text,\n",
        "        )]\n",
        "        conversations.append(conv)\n",
        "\n",
        "    # Batched chat template\n",
        "    inputs = processor.apply_chat_template(\n",
        "        conversations,\n",
        "        tokenize=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=False,\n",
        "        )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    new_tokens = outputs[:, input_ids.shape[1]:]\n",
        "    decoded_list = processor.batch_decode(new_tokens, skip_special_tokens=True)\n",
        "\n",
        "    labels = [normalize_label(text) for text in decoded_list]\n",
        "    return labels\n",
        "\n",
        "\n",
        "def run_batched_predictions(df: pd.DataFrame,\n",
        "                            batch_size: int = 4) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Full fast prediction over df using batched Voxtral calls.\n",
        "    Adds:\n",
        "        pred_audio : audio-only prediction\n",
        "        pred_both  : audio+transcript prediction\n",
        "    \"\"\"\n",
        "    df_eval = df.reset_index(drop=True).copy()\n",
        "\n",
        "    all_pa = []\n",
        "    all_pb = []\n",
        "\n",
        "    n = len(df_eval)\n",
        "    n_batches = (n + batch_size - 1) // batch_size\n",
        "\n",
        "    for start in tqdm(range(0, n, batch_size), total=n_batches):\n",
        "        end = min(start + batch_size, n)\n",
        "        batch = df_eval.iloc[start:end]\n",
        "\n",
        "        # Audio only\n",
        "        batch_pa = voxtral_predict_batch(batch, use_text=False)\n",
        "        # Audio + transcript\n",
        "        batch_pb = voxtral_predict_batch(batch, use_text=True)\n",
        "\n",
        "        all_pa.extend(batch_pa)\n",
        "        all_pb.extend(batch_pb)\n",
        "\n",
        "    df_eval[\"pred_audio\"] = all_pa\n",
        "    df_eval[\"pred_both\"]  = all_pb\n",
        "\n",
        "    return df_eval"
      ],
      "metadata": {
        "id": "JP_vjGqZ72fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. RUN FAST PREDICTIONS\n",
        "# ============================================\n",
        "# Tune batch_size based on GPU memory; 2–4 is usually safe, go higher if you can.\n",
        "df_eval = run_batched_predictions(df, batch_size=8)\n",
        "df_eval.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380,
          "referenced_widgets": [
            "1653b5639bca458b8647727ddf7cc145",
            "4da26cfee56d4ce0a00a1437d0d9bbdd",
            "631554640100411682e2d4473949df95",
            "143715811c0847ffa16f30afa2baaaff",
            "7701bfabf3b34c76a0c8f7e9467a6ec6",
            "da52c683bf71401eb9f318429b699ea3",
            "38757bf0cbe24357850260eaf0032282",
            "8d1163e136e94c918c7ffa611f0aab12",
            "6d580236723b46a6888f086d7e94962f",
            "8f51a2d4710f46a0949e71f7f225f45b",
            "b84b3bf3c47140bf88a9947f1a3a7308"
          ]
        },
        "id": "MSgbtKBe72-6",
        "outputId": "855de5ef-c825-4e30-92bc-25eb6ecb8f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1750 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1653b5639bca458b8647727ddf7cc145"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3403504239.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Tune batch_size based on GPU memory; 2–4 is usually safe, go higher if you can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_batched_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1421504348.py\u001b[0m in \u001b[0;36mrun_batched_predictions\u001b[0;34m(df, batch_size)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Audio only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mbatch_pa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoxtral_predict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Audio + transcript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbatch_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoxtral_predict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1421504348.py\u001b[0m in \u001b[0;36mvoxtral_predict_batch\u001b[0;34m(df_batch, use_text, max_new_tokens)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         outputs = model.generate(\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_prefill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2784\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2785\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/voxtral/modeling_voxtral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_features, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         outputs: BaseModelOutputWithPast = self.language_model(\n\u001b[0m\u001b[1;32m    524\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 459\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotary_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;31m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/pull/115074\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 7. METRICS & COMPARISON (UNCHANGED LOGIC)\n",
        "# ============================================\n",
        "y_true = df_eval[\"emotion\"].values\n",
        "y_pa   = df_eval[\"pred_audio\"].values\n",
        "y_pb   = df_eval[\"pred_both\"].values\n",
        "\n",
        "print(\"Label set in ground truth:\", sorted(set(y_true)))\n",
        "print(\"Label set in audio preds :\", sorted(set(y_pa)))\n",
        "print(\"Label set in audio+text  :\", sorted(set(y_pb)))\n",
        "\n",
        "acc_audio = accuracy_score(y_true, y_pa)\n",
        "acc_both  = accuracy_score(y_true, y_pb)\n",
        "\n",
        "f1m_audio = f1_score(y_true, y_pa, labels=LABELS, average=\"macro\")\n",
        "f1m_both  = f1_score(y_true, y_pb, labels=LABELS, average=\"macro\")\n",
        "\n",
        "print(\"\\n=== Global metrics ===\")\n",
        "print(f\"Accuracy (audio only) : {acc_audio: .3f}\")\n",
        "print(f\"Accuracy (audio+text) : {acc_both:  .3f}\")\n",
        "print(f\"Macro-F1 (audio only) : {f1m_audio: .3f}\")\n",
        "print(f\"Macro-F1 (audio+text) : {f1m_both:  .3f}\")\n",
        "\n",
        "print(\"\\n=== Audio only – classification report ===\")\n",
        "print(classification_report(y_true, y_pa, labels=LABELS))\n",
        "\n",
        "print(\"\\n=== Audio + transcript – classification report ===\")\n",
        "print(classification_report(y_true, y_pb, labels=LABELS))\n",
        "\n",
        "cm_audio = confusion_matrix(y_true, y_pa, labels=LABELS)\n",
        "cm_both  = confusion_matrix(y_true, y_pb, labels=LABELS)\n",
        "\n",
        "print(\"\\nConfusion matrix – audio only (rows = true, cols = pred):\")\n",
        "print(pd.DataFrame(cm_audio, index=LABELS, columns=LABELS))\n",
        "\n",
        "print(\"\\nConfusion matrix – audio + text (rows = true, cols = pred):\")\n",
        "print(pd.DataFrame(cm_both, index=LABELS, columns=LABELS))"
      ],
      "metadata": {
        "id": "xA9OyZdJ78-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 8. PLOTS (UNCHANGED, BUT NOW ON df_eval)\n",
        "# ============================================\n",
        "systems = [\"Audio only\", \"Audio + text\"]\n",
        "accs = [acc_audio, acc_both]\n",
        "f1s  = [f1m_audio, f1m_both]\n",
        "\n",
        "x = np.arange(len(systems))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(x - width/2, accs, width, label=\"Accuracy\")\n",
        "plt.bar(x + width/2, f1s,  width, label=\"Macro-F1\")\n",
        "plt.xticks(x, systems, rotation=0)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Voxtral zero-shot on ESD (English)\")\n",
        "plt.legend()\n",
        "plt.grid(axis=\"y\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "_, _, f1_audio_per_class, _ = precision_recall_fscore_support(\n",
        "    y_true, y_pa, labels=LABELS, average=None\n",
        ")\n",
        "_, _, f1_both_per_class, _ = precision_recall_fscore_support(\n",
        "    y_true, y_pb, labels=LABELS, average=None\n",
        ")\n",
        "\n",
        "x = np.arange(len(LABELS))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(x - width/2, f1_audio_per_class, width, label=\"Audio only\")\n",
        "plt.bar(x + width/2, f1_both_per_class,  width, label=\"Audio + text\")\n",
        "plt.xticks(x, LABELS, rotation=45)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.title(\"Per-class F1: audio vs audio+transcript\")\n",
        "plt.legend()\n",
        "plt.grid(axis=\"y\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8XfpsOcE8Aoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# EXTRA EVALUATION + PLOTLY VISUALIZATIONS\n",
        "# ============================================\n",
        "\n",
        "!pip install -q plotly\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# 1) PER-EMOTION METRICS TABLE\n",
        "# ----------------------------\n",
        "\n",
        "prec_a, rec_a, f1_a, sup = precision_recall_fscore_support(\n",
        "    y_true, y_pa, labels=LABELS, zero_division=0\n",
        ")\n",
        "prec_b, rec_b, f1_b, _ = precision_recall_fscore_support(\n",
        "    y_true, y_pb, labels=LABELS, zero_division=0\n",
        ")\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    \"emotion\": LABELS,\n",
        "    \"precision_audio\": prec_a,\n",
        "    \"recall_audio\":    rec_a,\n",
        "    \"f1_audio\":        f1_a,\n",
        "    \"precision_both\":  prec_b,\n",
        "    \"recall_both\":     rec_b,\n",
        "    \"f1_both\":         f1_b,\n",
        "    \"support\":         sup,\n",
        "})\n",
        "display(metrics_df)\n"
      ],
      "metadata": {
        "id": "4t3JIE_B9NPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) PER-EMOTION F1 COMPARISON (GROUPED BAR)\n",
        "# ------------------------------------------\n",
        "\n",
        "fig_f1_bar = go.Figure()\n",
        "\n",
        "fig_f1_bar.add_bar(\n",
        "    x=metrics_df[\"emotion\"],\n",
        "    y=metrics_df[\"f1_audio\"],\n",
        "    name=\"Audio only\",\n",
        ")\n",
        "fig_f1_bar.add_bar(\n",
        "    x=metrics_df[\"emotion\"],\n",
        "    y=metrics_df[\"f1_both\"],\n",
        "    name=\"Audio + text\",\n",
        ")\n",
        "\n",
        "fig_f1_bar.update_layout(\n",
        "    barmode=\"group\",\n",
        "    title=\"Per-emotion F1: audio vs audio+text\",\n",
        "    xaxis_title=\"Emotion\",\n",
        "    yaxis_title=\"F1-score\",\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    template=\"plotly_white\",\n",
        ")\n",
        "fig_f1_bar.show()\n"
      ],
      "metadata": {
        "id": "rO518MoO9Rz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) PER-EMOTION F1 SCATTER (WHICH EMOTIONS BENEFIT FROM TEXT?)\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "fig_f1_scatter = go.Figure()\n",
        "\n",
        "fig_f1_scatter.add_trace(go.Scatter(\n",
        "    x=metrics_df[\"f1_audio\"],\n",
        "    y=metrics_df[\"f1_both\"],\n",
        "    mode=\"markers+text\",\n",
        "    text=metrics_df[\"emotion\"],\n",
        "    textposition=\"top center\",\n",
        "    name=\"Emotions\",\n",
        "))\n",
        "\n",
        "# y = x reference line\n",
        "min_f1 = float(min(metrics_df[\"f1_audio\"].min(), metrics_df[\"f1_both\"].min()))\n",
        "max_f1 = float(max(metrics_df[\"f1_audio\"].max(), metrics_df[\"f1_both\"].max()))\n",
        "\n",
        "fig_f1_scatter.add_trace(go.Scatter(\n",
        "    x=[min_f1, max_f1],\n",
        "    y=[min_f1, max_f1],\n",
        "    mode=\"lines\",\n",
        "    line=dict(dash=\"dash\"),\n",
        "    name=\"y = x (no change)\",\n",
        "))\n",
        "\n",
        "fig_f1_scatter.update_layout(\n",
        "    title=\"F1(audio) vs F1(audio+text) per emotion\",\n",
        "    xaxis_title=\"F1 (audio only)\",\n",
        "    yaxis_title=\"F1 (audio + text)\",\n",
        "    xaxis=dict(range=[0, 1]),\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    template=\"plotly_white\",\n",
        ")\n",
        "fig_f1_scatter.show()"
      ],
      "metadata": {
        "id": "fZmbks3M9Tt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) CONFUSION MATRICES (HEATMAPS, PERCENTAGES)\n",
        "# ---------------------------------------------\n",
        "\n",
        "# Convert counts to percentages per true label for interpretability\n",
        "cm_audio_pct = cm_audio.astype(float) / cm_audio.sum(axis=1, keepdims=True)\n",
        "cm_both_pct  = cm_both.astype(float) / cm_both.sum(axis=1, keepdims=True)\n",
        "\n",
        "fig_cm_audio = px.imshow(\n",
        "    cm_audio_pct,\n",
        "    x=LABELS,\n",
        "    y=LABELS,\n",
        "    color_continuous_scale=\"Blues\",\n",
        "    labels=dict(x=\"Predicted\", y=\"True\", color=\"Proportion\"),\n",
        "    text_auto=\".2f\",\n",
        ")\n",
        "fig_cm_audio.update_layout(\n",
        "    title=\"Confusion matrix (audio only) – row-normalized\",\n",
        "    template=\"plotly_white\",\n",
        ")\n",
        "fig_cm_audio.show()\n",
        "\n",
        "fig_cm_both = px.imshow(\n",
        "    cm_both_pct,\n",
        "    x=LABELS,\n",
        "    y=LABELS,\n",
        "    color_continuous_scale=\"Greens\",\n",
        "    labels=dict(x=\"Predicted\", y=\"True\", color=\"Proportion\"),\n",
        "    text_auto=\".2f\",\n",
        ")\n",
        "fig_cm_both.update_layout(\n",
        "    title=\"Confusion matrix (audio + text) – row-normalized\",\n",
        "    template=\"plotly_white\",\n",
        ")\n",
        "fig_cm_both.show()\n"
      ],
      "metadata": {
        "id": "UQFnx2pM9Vc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) PER-SPEAKER ACCURACY (HOW CONSISTENT ACROSS SPEAKERS?)\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "def speaker_accuracy(df_eval, pred_col):\n",
        "    return (\n",
        "        df_eval\n",
        "        .assign(correct=lambda d: d[\"emotion\"] == d[pred_col])\n",
        "        .groupby(\"speaker\")[\"correct\"]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .rename(columns={\"correct\": f\"acc_{pred_col}\"})\n",
        "    )\n",
        "\n",
        "acc_spk_audio = speaker_accuracy(df_eval, \"pred_audio\")\n",
        "acc_spk_both  = speaker_accuracy(df_eval, \"pred_both\")\n",
        "\n",
        "acc_spk = acc_spk_audio.merge(acc_spk_both, on=\"speaker\")\n",
        "\n",
        "fig_spk = go.Figure()\n",
        "fig_spk.add_bar(\n",
        "    x=acc_spk[\"speaker\"],\n",
        "    y=acc_spk[\"acc_pred_audio\"],\n",
        "    name=\"Audio only\",\n",
        ")\n",
        "fig_spk.add_bar(\n",
        "    x=acc_spk[\"speaker\"],\n",
        "    y=acc_spk[\"acc_pred_both\"],\n",
        "    name=\"Audio + text\",\n",
        ")\n",
        "\n",
        "fig_spk.update_layout(\n",
        "    barmode=\"group\",\n",
        "    title=\"Per-speaker accuracy: audio vs audio+text\",\n",
        "    xaxis_title=\"Speaker ID\",\n",
        "    yaxis_title=\"Accuracy\",\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    template=\"plotly_white\",\n",
        ")\n",
        "fig_spk.show()\n"
      ],
      "metadata": {
        "id": "6xCmp7rB9XV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) UNKNOWN PREDICTIONS & CLASS BALANCE\n",
        "# --------------------------------------\n",
        "\n",
        "unknown_audio = (df_eval[\"pred_audio\"] == \"Unknown\").sum()\n",
        "unknown_both  = (df_eval[\"pred_both\"]  == \"Unknown\").sum()\n",
        "\n",
        "print(f\"Unknown predictions (audio only): {unknown_audio}\")\n",
        "print(f\"Unknown predictions (audio+text): {unknown_both}\")\n",
        "\n",
        "# Class distribution in ground truth\n",
        "emo_counts = df_eval[\"emotion\"].value_counts().reindex(LABELS).fillna(0)\n",
        "\n",
        "fig_dist = px.bar(\n",
        "    emo_counts,\n",
        "    x=emo_counts.index,\n",
        "    y=emo_counts.values,\n",
        "    labels={\"x\": \"Emotion\", \"y\": \"Count\"},\n",
        "    title=\"Class distribution in ESD-English subset\",\n",
        "    template=\"plotly_white\",\n",
        ")\n",
        "fig_dist.show()"
      ],
      "metadata": {
        "id": "IiZMbGTB9ZWl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}